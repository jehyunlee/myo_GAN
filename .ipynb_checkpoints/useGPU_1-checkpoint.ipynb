{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0+cu101'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DEVICE 0: Tesla V100-PCIE-32GB\n",
      "- Memory Usage:\n",
      "  Allocated: 0.0 GB\n",
      "  Cached:    0.0 GB\n",
      "\n",
      "# DEVICE 1: Tesla V100-PCIE-32GB\n",
      "- Memory Usage:\n",
      "  Allocated: 0.0 GB\n",
      "  Cached:    0.0 GB\n",
      "\n",
      "# DEVICE 2: Tesla V100-PCIE-32GB\n",
      "- Memory Usage:\n",
      "  Allocated: 0.0 GB\n",
      "  Cached:    0.0 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"# DEVICE {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(\"- Memory Usage:\")\n",
    "        print(f\"  Allocated: {round(torch.cuda.memory_allocated(i)/1024**3,1)} GB\")\n",
    "        print(f\"  Cached:    {round(torch.cuda.memory_cached(i)/1024**3,1)} GB\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"# GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Current cuda device:  0\n"
     ]
    }
   ],
   "source": [
    "# GPU 할당 변경하기\n",
    "GPU_NUM = 0 # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "\n",
    "print ('# Current cuda device: ', torch.cuda.current_device()) # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda: 0, Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    print(f\"using cuda: {GPU_NUM}, {torch.cuda.get_device_name(GPU_NUM)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data_df = pd.read_csv(csv_file, header=None)\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.data_df.iloc[index, 0]\n",
    "        target = torch.zeros((10))\n",
    "        target[label] = 1.0\n",
    "        \n",
    "        image_values = torch.Tensor(self.data_df.iloc[index, 1:].values)/255.0\n",
    "        \n",
    "        return label, image_values, target\n",
    "    \n",
    "    def plot_image(self, index):\n",
    "        img = self.data_df.iloc[index, 1:].values.reshape(28, 28)\n",
    "        plt.title(f\"label = {self.data_df.iloc[index, 0]}\")\n",
    "        plt.imshow(img, interpolation='none', cmap='Blues')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_dataset = MnistDataset(\"./myo_gan/mnist_train.csv\")\n",
    "mnist_dataset.plot_image(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_image(size):\n",
    "    random_data = torch.rand(size)\n",
    "    return random_data\n",
    "\n",
    "def generate_random_seed(size):\n",
    "    random_data = torch.randn(size)\n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_random_image(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_random_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 200),\n",
    "            nn.LeakyReLU(0.02),\n",
    "            nn.LayerNorm(200),\n",
    "            nn.Linear(200, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "        self.loss_function = nn.BCELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        \n",
    "        self.counter = 0\n",
    "        self.progress = []\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs)\n",
    "    \n",
    "    def train(self, inputs, targets):\n",
    "        outputs = self.forward(inputs)\n",
    "        \n",
    "        loss = self.loss_function(outputs, targets)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        self.counter += 1\n",
    "        if self.counter % 10 == 0:\n",
    "            self.progress.append(loss.item())\n",
    "        if self.counter % 10000 == 0:\n",
    "            print(f\"counter= {self.counter}\")\n",
    "            \n",
    "    def plot_progress(self):\n",
    "        df = pd.DataFrame(self.progress, columns=[\"loss\"])\n",
    "        df.plot(ylim=(0), figsize=(16, 8), alpha=0.1, marker=\".\", grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator()\n",
    "\n",
    "for label, image_data_tensor, target_tensor in mnist_dataset:\n",
    "    # real data\n",
    "    D.train(image_data_tensor, torch.Tensor([1.0]))\n",
    "    \n",
    "    # fake data\n",
    "    D.train(generate_random_image(784), torch.Tensor([0.0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in range(4):\n",
    "    image_data_tensor = mnist_dataset[random.randint(0, 60000)][1]\n",
    "    print(D.forward(image_data_tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(D.forward(generate_random_image(784)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 200),\n",
    "            nn.LeakyReLU(0.02),\n",
    "            nn.LayerNorm(200),\n",
    "            nn.Linear(200, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        \n",
    "        self.counter = 0\n",
    "        self.progress = []\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs)\n",
    "    \n",
    "    def train(self, D, inputs, targets):\n",
    "        g_output = self.forward(inputs)\n",
    "        \n",
    "        d_output = D.forward(g_output)\n",
    "        \n",
    "        loss = D.loss_function(d_output, targets)\n",
    "        \n",
    "        self.counter += 1\n",
    "        if self.counter % 10 == 0:\n",
    "            self.progress.append(loss.item())\n",
    "            \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def plot_progress(self):\n",
    "        df = pd.DataFrame(self.progress, columns=[\"loss\"])\n",
    "        df.plot(ylim=(0), figsize=(16, 8), alpha=0.1, marker=\".\", grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "\n",
    "output = G.forward(generate_random_seed(100))\n",
    "img = output.cpu().detach().numpy().reshape(28, 28)\n",
    "plt.imshow(img, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "D = Discriminator()\n",
    "G = Generator()\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch= {epoch+1}\")\n",
    "    \n",
    "    for label, image_data_tensor, target_tensor in mnist_dataset:\n",
    "        D.train(image_data_tensor, torch.Tensor([1.0]))\n",
    "        D.train(G.forward(generate_random_seed(100)).detach(), torch.Tensor([0.0]))\n",
    "        G.train(D, generate_random_seed(100), torch.Tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(16, 8))\n",
    "for ax in axes.ravel():\n",
    "    output = G.forward(generate_random_seed(100))\n",
    "    img = output.cpu().detach().numpy().reshape(28, 28)\n",
    "    ax.imshow(img, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784+10, 200),\n",
    "            nn.LeakyReLU(0.02),\n",
    "            nn.LayerNorm(200),\n",
    "            nn.Linear(200, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "        self.loss_function = nn.BCELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        \n",
    "        self.counter = 0\n",
    "        self.progress = []\n",
    "        \n",
    "    def forward(self, image_tensor, label_tensor):\n",
    "        inputs = torch.cat((image_tensor, label_tensor))\n",
    "        return self.model(inputs)\n",
    "    \n",
    "    def train(self, inputs, label_tensor, targets):\n",
    "        outputs = self.forward(inputs, label_tensor)\n",
    "        \n",
    "        loss = self.loss_function(outputs, targets)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        self.counter += 1\n",
    "        if self.counter % 10 == 0:\n",
    "            self.progress.append(loss.item())\n",
    "        if self.counter % 10000 == 0:\n",
    "            print(f\"counter= {self.counter}\")\n",
    "            \n",
    "    def plot_progress(self):\n",
    "        df = pd.DataFrame(self.progress, columns=[\"loss\"])\n",
    "        df.plot(ylim=(0), figsize=(16, 8), alpha=0.1, marker=\".\", grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_one_hot(size):\n",
    "    label_tensor = torch.zeros((size))\n",
    "    random_idx = random.randint(0, size-1)\n",
    "    label_tensor[random_idx] = 1.0\n",
    "    return label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator()\n",
    "\n",
    "for label, image_data_tensor, label_tensor in mnist_dataset:\n",
    "    D.train(image_data_tensor, label_tensor, torch.Tensor([1.0]))\n",
    "    D.train(generate_random_image(784), generate_random_one_hot(10), torch.Tensor([0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100+10, 200),\n",
    "            nn.LeakyReLU(0.02),\n",
    "            nn.LayerNorm(200),\n",
    "            nn.Linear(200, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        \n",
    "        self.counter = 0\n",
    "        self.progress = []\n",
    "        \n",
    "    def forward(self, seed_tensor, label):\n",
    "        inputs = torch.cat((seed_tensor, label))\n",
    "        return self.model(inputs)\n",
    "    \n",
    "    def train(self, D, inputs, label_tensor, targets):\n",
    "        g_output = self.forward(inputs, label_tensor)\n",
    "        \n",
    "        d_output = D.forward(g_output, label_tensor)\n",
    "        \n",
    "        loss = D.loss_function(d_output, targets)\n",
    "        \n",
    "        self.counter += 1\n",
    "        if self.counter % 10 == 0:\n",
    "            self.progress.append(loss.item())\n",
    "            \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def plot_progress(self):\n",
    "        df = pd.DataFrame(self.progress, columns=[\"loss\"])\n",
    "        df.plot(ylim=(0), figsize=(16, 8), alpha=0.1, marker=\".\", grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
    "        \n",
    "    def plot_images(self, label):\n",
    "        label_tensor = torch.zeros((10))\n",
    "        label_tensor[label] = 1.0\n",
    "\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "        for ax in axes.ravel():\n",
    "            ax.imshow(G.forward(generate_random_seed(100), label_tensor).detach().cpu().numpy().reshape(28, 28), cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator()\n",
    "G = Generator()\n",
    "\n",
    "epochs = 12\n",
    "for epoch in range(epochs):\n",
    "    for label, image_data_tensor, label_tensor in mnist_dataset:\n",
    "        D.train(image_data_tensor, label_tensor, torch.Tensor([1.0]))\n",
    "\n",
    "        random_label = generate_random_one_hot(10)\n",
    "        D.train(G.forward(generate_random_seed(100), random_label).detach(), random_label, torch.Tensor([0.0]))\n",
    "\n",
    "        random_label = generate_random_one_hot(10)\n",
    "        G.train(D, generate_random_seed(100), random_label, torch.Tensor([1.0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot_images(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator class\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initialise parent pytorch class\n",
    "        super().__init__()\n",
    "        \n",
    "        # define neural network layers\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100+10, 200),\n",
    "            nn.LeakyReLU(0.02),\n",
    "\n",
    "            nn.LayerNorm(200),\n",
    "\n",
    "            nn.Linear(200, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "        # create optimiser, simple stochastic gradient descent\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "\n",
    "        # counter and accumulator for progress\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, seed_tensor, label_tensor):        \n",
    "        # combine seed and label\n",
    "        inputs = torch.cat((seed_tensor, label_tensor))\n",
    "        return self.model(inputs)\n",
    "\n",
    "\n",
    "    def train(self, D, inputs, label_tensor, targets):\n",
    "        # calculate the output of the network\n",
    "        g_output = self.forward(inputs, label_tensor)\n",
    "        \n",
    "        # pass onto Discriminator\n",
    "        d_output = D.forward(g_output, label_tensor)\n",
    "        \n",
    "        # calculate error\n",
    "        loss = D.loss_function(d_output, targets)\n",
    "\n",
    "        # increase counter and accumulate error every 10\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "            pass\n",
    "\n",
    "        # zero gradients, perform a backward pass, update weights\n",
    "        self.optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimiser.step()\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def plot_images(self, label):\n",
    "        label_tensor = torch.zeros((10))\n",
    "        label_tensor[label] = 1.0\n",
    "        # plot a 3 column, 2 row array of sample images\n",
    "        f, axarr = plt.subplots(2,3, figsize=(16,8))\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                axarr[i,j].imshow(G.forward(generate_random_seed(100), label_tensor).detach().cpu().numpy().reshape(28,28), interpolation='none', cmap='Blues')\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    \n",
    "    def plot_progress(self):\n",
    "        df = pd.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Discriminator and Generator\n",
    "\n",
    "D = Discriminator()\n",
    "G = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# train Discriminator and Generator\n",
    "\n",
    "epochs = 12\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print (\"epoch = \", epoch + 1)\n",
    "\n",
    "    # train Discriminator and Generator\n",
    "\n",
    "    for label, image_data_tensor, label_tensor in mnist_dataset:\n",
    "        # train discriminator on true\n",
    "        D.train(image_data_tensor, label_tensor, torch.Tensor([1.0]))\n",
    "\n",
    "        # random 1-hot label for generator\n",
    "        random_label = generate_random_one_hot(10)\n",
    "\n",
    "        # train discriminator on false\n",
    "        # use detach() so gradients in G are not calculated\n",
    "        D.train(G.forward(generate_random_seed(100), random_label).detach(), random_label, torch.Tensor([0.0]))\n",
    "\n",
    "        # different random 1-hot label for generator\n",
    "        random_label = generate_random_one_hot(10)\n",
    "\n",
    "        # train generator\n",
    "        G.train(D, generate_random_seed(100), random_label, torch.Tensor([1.0]))\n",
    "\n",
    "        pass\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot_images(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
